{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5da5c6e-d6a3-4783-9fcc-cbf786323861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052d57e5-49a4-4770-87e7-d185f314ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f'data/' + 'Higgs' + '.npz', allow_pickle=True)\n",
    "X_train, X_test, y_train, y_test = data['X_train'], data['X_test'], data['y_train'], data['y_test']\n",
    "eval_sets = [{'X': X_test, 'y': y_test},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d26352-e38b-4024-9c14-c9c5fc772219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_boost\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f34aec-750f-4964-b697-7500bd9ad86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'ds_name': 'Higgs',\n",
    " 'order': 2,\n",
    " 'ntrees': 2000,\n",
    " 'max_depth': 6,\n",
    " 'lambda_l2': [35000000, 40000000, 50000000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36edffec-38d8-4fb5-b182-6b184e758f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:51] Stdout logging level is INFO.\n",
      "[12:49:51] GDBT train starts. Max iter 2000, early stopping rounds 3000\n",
      "[12:49:52] Iter 0; Sample 0, BCE = 0.6843453899471912; \n",
      "[12:49:54] Iter 100; Sample 0, BCE = 0.5419820775004266; \n",
      "[12:49:55] Iter 200; Sample 0, BCE = 0.5299685359303842; \n",
      "[12:49:57] Iter 300; Sample 0, BCE = 0.5246041260331503; \n",
      "[12:49:58] Iter 400; Sample 0, BCE = 0.521220768538477; \n",
      "[12:50:00] Iter 500; Sample 0, BCE = 0.5189205175162319; \n",
      "[12:50:02] Iter 600; Sample 0, BCE = 0.5169584115624718; \n",
      "[12:50:03] Iter 700; Sample 0, BCE = 0.5157532096865431; \n",
      "[12:50:05] Iter 800; Sample 0, BCE = 0.5146248088456306; \n",
      "[12:50:07] Iter 900; Sample 0, BCE = 0.5135592083848033; \n",
      "[12:50:08] Iter 1000; Sample 0, BCE = 0.5125492640051984; \n",
      "[12:50:10] Iter 1100; Sample 0, BCE = 0.5113096495703371; \n",
      "[12:50:12] Iter 1200; Sample 0, BCE = 0.5107451943375693; \n",
      "[12:50:13] Iter 1300; Sample 0, BCE = 0.5101457953674433; \n",
      "[12:50:15] Iter 1400; Sample 0, BCE = 0.5097397655064948; \n",
      "[12:50:16] Iter 1500; Sample 0, BCE = 0.5094237419978443; \n",
      "[12:50:18] Iter 1600; Sample 0, BCE = 0.5090173750695294; \n",
      "[12:50:20] Iter 1700; Sample 0, BCE = 0.5087058955445718; \n",
      "[12:50:21] Iter 1800; Sample 0, BCE = 0.5084843079968696; \n",
      "[12:50:23] Iter 1900; Sample 0, BCE = 0.5081766275178553; \n",
      "[12:50:25] Iter 1999; Sample 0, BCE = 0.5079273682614932; \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f38a36d5e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py_boost import GradientBoosting\n",
    "\n",
    "model = GradientBoosting(loss='bce', ntrees=params['ntrees'], max_depth=params['max_depth'], lambda_l2=1, es=3000, verbose=100)\n",
    "model.fit(X_train, y_train, eval_sets=[{'X': X_test, 'y': y_test},])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc4b7d-29d0-4f62-bb0c-dbcdd3599c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:05] Stdout logging level is INFO.\n",
      "[12:52:05] GDBT train starts. Max iter 2000, early stopping rounds 3000\n",
      "[12:52:05] Iter 0; Sample 0, BCE = 0.6843273480053482; \n",
      "[12:52:06] Iter 100; Sample 0, BCE = 0.5411662070199985; \n",
      "[12:52:07] Iter 200; Sample 0, BCE = 0.5291740436447329; \n",
      "[12:52:08] Iter 300; Sample 0, BCE = 0.5234448564334631; \n",
      "[12:52:10] Iter 400; Sample 0, BCE = 0.5202849676436943; \n",
      "[12:52:11] Iter 500; Sample 0, BCE = 0.5179206545307901; \n",
      "[12:52:12] Iter 600; Sample 0, BCE = 0.5158932322920907; \n",
      "[12:52:13] Iter 700; Sample 0, BCE = 0.5144273753853174; \n",
      "[12:52:14] Iter 800; Sample 0, BCE = 0.5132767392273282; \n",
      "[12:52:16] Iter 900; Sample 0, BCE = 0.512344861180664; \n",
      "[12:52:17] Iter 1000; Sample 0, BCE = 0.5116606179095617; \n",
      "[12:52:18] Iter 1100; Sample 0, BCE = 0.511052060357825; \n",
      "[12:52:19] Iter 1200; Sample 0, BCE = 0.5105790238883142; \n",
      "[12:52:20] Iter 1300; Sample 0, BCE = 0.5102339961306555; \n",
      "[12:52:21] Iter 1400; Sample 0, BCE = 0.5098208009055226; \n",
      "[12:52:23] Iter 1500; Sample 0, BCE = 0.5095397217732665; \n",
      "[12:52:24] Iter 1600; Sample 0, BCE = 0.5092326755916897; \n",
      "[12:52:25] Iter 1700; Sample 0, BCE = 0.5089604552645156; \n",
      "[12:52:26] Iter 1800; Sample 0, BCE = 0.5088043555905035; \n"
     ]
    }
   ],
   "source": [
    "model = GradientBoosting(loss='bce', ntrees=params['ntrees'], colsample=1.,subsample=0.5, max_depth=params['max_depth'], lambda_l2=1, es=3000, verbose=100)\n",
    "model.fit(X_train, y_train, eval_sets=[{'X': X_test, 'y': y_test},])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d895bc8-bf39-48a8-8cca-2fc9c5022555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
