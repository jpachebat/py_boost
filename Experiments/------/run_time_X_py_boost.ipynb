{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7e1663-16c0-435c-a7d9-d35b21b2413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.14.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import numpy as np\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "def get_results(model):\n",
    "    return list(np.array(model.history).reshape(len(model.history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307d467-e6c7-4188-a183-7e586eb1ce51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f5e38c-b6e8-415b-9814-44cac4d89658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192000, 28) (48000, 28) (60000, 28)\n",
      "(192000,) (48000,) (60000,)\n"
     ]
    }
   ],
   "source": [
    "## Higgs dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('HIGGS.csv', nrows=300000)\n",
    "df.columns = ['label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
    "df[\"label\"] = df[\"label\"].apply(int)\n",
    "\n",
    "df_train = df\n",
    "\n",
    "X = df_train.iloc[:, 1:].to_numpy()\n",
    "y = df_train['label'].to_numpy()\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "X_t, X_test, y_t, y_test = train_test_split(X_std, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adce5c69-2c10-4caa-bea9-d515c197927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import X_py_boost\n",
    "\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e360fd9-979e-4537-a367-8855a8bc4a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:58] Stdout logging level is INFO.\n",
      "[13:26:58] GDBT train starts. Max iter 10000, early stopping rounds 100\n",
      "[13:26:58] Iter 0; Sample 0, BCE = 0.6808722394887633; \n",
      "[13:27:20] Iter 1000; Sample 0, BCE = 0.2979169106630678; \n",
      "[13:27:42] Iter 2000; Sample 0, BCE = 0.1775872988357166; \n",
      "[13:28:16] Iter 3000; Sample 0, BCE = 0.1022526836127296; \n",
      "[13:28:37] Iter 4000; Sample 0, BCE = 0.0579561273764996; \n",
      "[13:28:56] Iter 5000; Sample 0, BCE = 0.03175186578447297; \n",
      "[13:29:16] Iter 6000; Sample 0, BCE = 0.01748727604656775; \n",
      "[13:29:45] Iter 7000; Sample 0, BCE = 0.009626502441611881; \n",
      "[13:30:04] Iter 8000; Sample 0, BCE = 0.005275171896412787; \n",
      "[13:30:24] Iter 9000; Sample 0, BCE = 0.0028938717238380777; \n",
      "[13:30:43] Iter 9999; Sample 0, BCE = 0.0015892086136149082; \n",
      "time per iteration: 0.022440025353431703\n"
     ]
    }
   ],
   "source": [
    "from X_py_boost import GradientBoosting\n",
    "import time\n",
    "\n",
    "m_d=8\n",
    "eval_sets=[{'X': X_train, 'y': y_train},]\n",
    "## Order 2\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2 = GradientBoosting(loss='bce4', ntrees=10000, max_depth=m_d, lambda_l2=0.001, verbose=1000)\n",
    "model2.fit(X_train, y_train, eval_sets=eval_sets)\n",
    "\n",
    "end = time.time()\n",
    "time2 = end - start\n",
    "time_per_iter = time2 / len(get_results(model2))\n",
    "\n",
    "print(f\"time per iteration: {time_per_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a768e837-90be-4fe7-b6b8-2f5dd2c4a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:00] Stdout logging level is INFO.\n",
      "[13:31:00] GDBT train starts. Max iter 10000, early stopping rounds 100\n",
      "[13:31:00] Iter 0; Sample 0, BCE = 0.6807538053307209; \n",
      "[13:31:21] Iter 1000; Sample 0, BCE = 0.30178592673476917; \n",
      "[13:31:42] Iter 2000; Sample 0, BCE = 0.18780567407077722; \n",
      "[13:32:03] Iter 3000; Sample 0, BCE = 0.11453959955884514; \n",
      "[13:32:23] Iter 4000; Sample 0, BCE = 0.06943461362642313; \n",
      "[13:32:42] Iter 5000; Sample 0, BCE = 0.041780478410820034; \n",
      "[13:33:02] Iter 6000; Sample 0, BCE = 0.025383991734773275; \n",
      "[13:33:21] Iter 7000; Sample 0, BCE = 0.015454139176161355; \n",
      "[13:33:41] Iter 8000; Sample 0, BCE = 0.009437699747234136; \n",
      "[13:34:00] Iter 9000; Sample 0, BCE = 0.005750510658980616; \n",
      "[13:34:20] Iter 9999; Sample 0, BCE = 0.003545961907847208; \n",
      "time per iteration: 0.020005656361579895\n"
     ]
    }
   ],
   "source": [
    "from X_py_boost import GradientBoosting\n",
    "import time\n",
    "\n",
    "m_d=8\n",
    "eval_sets=[{'X': X_train, 'y': y_train},]\n",
    "## Order 2\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2 = GradientBoosting(loss='bce2', ntrees=10000, max_depth=m_d, lambda_l2=0.001, verbose=1000)\n",
    "model2.fit(X_train, y_train, eval_sets=eval_sets)\n",
    "\n",
    "end = time.time()\n",
    "time2 = end - start\n",
    "time_per_iter = time2 / len(get_results(model2))\n",
    "\n",
    "print(f\"time per iteration: {time_per_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bdfbb6-38f0-41cb-ac29-2e19a1c721a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:20] Stdout logging level is INFO.\n",
      "[13:34:20] GDBT train starts. Max iter 10000, early stopping rounds 100\n",
      "[13:34:20] Iter 0; Sample 0, BCE = 0.6807689830584379; \n",
      "[13:34:24] Early stopping at iter 179, best iter 79, best_score 0.4984669871993616\n",
      "time per iteration: 0.021450765972030897\n"
     ]
    }
   ],
   "source": [
    "from X_py_boost import GradientBoosting\n",
    "import time\n",
    "\n",
    "m_d=8\n",
    "eval_sets=[{'X': X_train, 'y': y_train},]\n",
    "## Order 2\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model2 = GradientBoosting(loss='bce3', ntrees=10000, max_depth=m_d, lambda_l2=0.001, verbose=1000)\n",
    "model2.fit(X_train, y_train, eval_sets=eval_sets)\n",
    "\n",
    "end = time.time()\n",
    "time2 = end - start\n",
    "time_per_iter = time2 / len(get_results(model2))\n",
    "\n",
    "print(f\"time per iteration: {time_per_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd18186-1058-41f5-89d8-2aa4cba0d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Â£"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
